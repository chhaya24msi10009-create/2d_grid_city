# **Autonomous Delivery Agent**

This project implements an autonomous agent that navigates a 2D grid city to deliver packages efficiently. The agent is designed to handle various environmental challenges, including static obstacles, different terrain costs, and dynamic obstacles. It uses several pathfinding algorithms to find optimal routes and replan when necessary.

## **Features**

* **Grid-Based Environment:** The city is modeled as a 2D grid with varying costs for movement.  
* **Pathfinding Algorithms:**  
  * **Uniform-Cost Search (UCS):** An uninformed search algorithm that finds the cheapest path.  
  * **A\* Search:** An informed search algorithm that uses the Manhattan distance heuristic for efficient pathfinding.  
* **Dynamic Replanning:**  
  * A local search strategy (**Hill-Climbing with Random Restarts**, implemented as a re-run of A\* from the current position) is used to handle unforeseen dynamic obstacles.  
* **Simulation and Analysis:** The project provides tools to run simulations, compare algorithm performance, and visualize the agent's path.

## **Directory Structure**

.  
├── agent.py               \# Contains the DeliveryAgent class with search algorithms.  
├── environment.py         \# Defines the GridCity environment.  
├── main.py                \# Main script to run simulations.  
├── maps/                  \# Directory for map files.  
│   ├── small\_map.txt  
│   ├── medium\_map.txt  
│   ├── large\_map.txt  
│   └── dynamic\_map.txt  
├── proof\_of\_concept.log   \# Example log file generated by the dynamic simulation.  
├── requirements.md        \# This README file.  
└── visualizer.py          \# Script to visualize the agent's path from a log file.

## **Map File Format**

The environment is defined in .txt files within the maps/ directory. The format is as follows:

* **Grid Cells:** Each cell represents a part of the city.  
  * S: Starting position of the agent (cost \= 1).  
  * G: Goal (delivery) position (cost \= 1).  
  * \#: A static, impassable obstacle (cost \= infinity).  
  * 1-9: Traversable terrain with the corresponding movement cost.  
* **Dynamic Obstacles:** Moving obstacles are defined on separate lines with the format M(y,x,t).  
  * y: The row coordinate.  
  * x: The column coordinate.  
  * t: The time step at which the obstacle is present at that location.

### **Example Map (dynamic\_map.txt)**

S-1-1-1-1  
1-\#-\#-1-1  
1-1-1-1-G  
1-\#-1-1-1  
1-1-1-\#-1  
M(1,3,3)  
M(2,4,6)

## **Setup and Dependencies**

1. **Clone the repository:**  
   git clone \<your-repo-url\>  
   cd \<your-repo-directory\>

2. **Install dependencies:** The project requires matplotlib and numpy for visualization.  
   pip install matplotlib numpy

## **Usage**

The simulation is controlled via the command line from main.py.

### **Running a Single Algorithm**

You can run a specific algorithm on a chosen map.

* **Uniform-Cost Search (UCS):**  
  python main.py \--map\_path maps/small\_map.txt \--algorithm ucs

* **A\* Search:**  
  python main.py \--map\_path maps/small\_map.txt \--algorithm a\_star

### **Simulating Dynamic Replanning**

To test the agent's ability to handle dynamic obstacles, run the dynamic algorithm. This will simulate the agent moving step-by-step and replanning if it encounters a moving obstacle. A proof\_of\_concept.log file will be generated.

python main.py \--map\_path maps/dynamic\_map.txt \--algorithm dynamic

### **Running Experiments for Comparison**

To compare the performance of UCS and A\* on a single map, use the \--run\_experiments flag.

python main.py \--map\_path maps/medium\_map.txt \--run\_experiments

This will run both algorithms sequentially and print a report for each, allowing you to compare Path Cost, Nodes Expanded, and Execution Time.

## **Visualization**

After running a dynamic simulation, you can visualize the agent's path, including where it encountered obstacles and had to replan.

Run the visualizer.py script with the map and the generated log file:

python visualizer.py \--map\_path maps/dynamic\_map.txt \--log\_path proof\_of\_concept.log

This will open a plot showing:

* The grid environment.  
* The agent's final path (purple line).  
* The location of dynamic obstacles (red circles).  
* Points where replanning was triggered (purple 'X').

## **Algorithm Details**

### **Uniform-Cost Search (UCS)**

An uninformed search algorithm that explores the grid by expanding the lowest-cost node first. It guarantees finding the cheapest path from start to goal but can be slow as it doesn't use any information about the goal's location.

### **A\* Search**

A best-first search algorithm that is both complete and optimal. It uses a heuristic function to guide its search towards the goal. In this project, we use the **Manhattan distance** as the heuristic, which is admissible because the agent can only move in four directions (up, down, left, right).

f(n)=g(n)+h(n)

* g(n): The actual cost from the start node to node n.  
* h(n): The estimated (heuristic) cost from node n to the goal.

### **Dynamic Replanning: Hill-Climbing**

When a dynamic obstacle is detected in the agent's planned path, a replanning strategy is initiated. This project uses a simplified but effective form of local search: the agent re-runs the A\* algorithm from its current position to find a new optimal path to the goal, avoiding the newly discovered obstacle. This is analogous to a "random restart" in Hill-Climbing, where the agent discards its old plan and generates a completely new one based on the updated state of the world.